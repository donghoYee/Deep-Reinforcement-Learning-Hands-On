{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44f1154f-028d-4eeb-93bf-4b807cc903c7",
   "metadata": {},
   "source": [
    "# Deep Learning with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b57b7b48-0d9c-4cbd-ba2f-e6a6c728f144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "427900bd-296f-4ff3-8fe0-8a7b929b7875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.8019e+30, 2.0700e-19],\n",
      "        [2.6793e+20, 4.7420e+30],\n",
      "        [2.3745e+23, 3.0357e+32]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.FloatTensor(3, 2)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cf1a9e2-4bf0-4e08-926c-3bdf1877cebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.zero_()  # initialize tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7efcf50-5fa3-4d74-85da-4f4596acb3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.FloatTensor([[1,2,3],[3,2,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffff1d71-7111-4650-ad63-f1226797a5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [3., 2., 1.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7a05dc1-7ca9-4fde-b99a-d5f7a2e39e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.zeros(shape=(3,2))\n",
    "c = torch.tensor(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da7b08da-ee59-48c6-bf91-1a09d3239326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "118a0a14-0b66-4795-8462-2af15e2726b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.zeros(shape=(3,2), dtype=np.float32)\n",
    "c = torch.tensor(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f00d87f1-423e-4749-82fa-ff2db335219e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "edc11ca8-b070-41d0-b0cb-ff5772bad64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15f58c59-b368-468a-afcc-f4b7a015fac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = b.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57eb9cc5-9f07-4c08-9116-cc910c0a65ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4060472b-7f65-45c3-bfac-1113e5c302a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e326078e-7f77-43f6-b3d8-3bc04d7e1b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3519430d-7698-40e5-951a-aa39f916e84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8dcb1369-dc3d-45b1-be7f-050c153514ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = b.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "319efc26-e713-4307-8ea3-3303e1f61dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [3., 2., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90e5657c-5ae0-4483-a2e1-c536e112f4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 4.],\n",
       "        [4., 3., 2.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d925794f-e832-4c7f-bbec-74d91617be4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3., 4.],\n",
       "        [4., 3., 2.]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18454d2c-fba5-4d13-a6b4-8e4dccc65c72",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2151cba9-5df3-4ed7-834c-ba3f43dcec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.tensor([1.0, 1.0], requires_grad=True)\n",
    "v2 = torch.tensor([2.0, 2.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "517273e0-abf5-4880-a1c5-d9c16d70419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_sum= v1 + v2\n",
    "v_res = (v_sum*2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e01b3e9-bab3-4bd2-abd9-936e1b7c8dcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "664a6004-00b1-4cd6-b8d2-b319f3081d20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.is_leaf, v2.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d32c78b-71cf-465c-834f-e36e4cc4de73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.is_leaf, v_res.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a5615aa-e45f-42cf-94ab-ed20c7869d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "97981941-d7a6-4275-af38-47c8026b6da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5813fad-f3d8-4ad5-945f-f03a1b66928c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_res.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8c8f8630-ecbe-40f1-ad56-50ad98a22a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_sum.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c8092481-cf07-45ff-81a9-b69641ad0f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_res.backward() # calculate gradient of our graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cc72664-06e9-4d08-a870-fc579ea24efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23797226-ac1a-4fff-8dff-5b7117e78149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(v2.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fa62d51-a057-423b-85e4-5bca963660b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dongho/anaconda3/envs/DRLH/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "v_res.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead3856e-72e5-4057-87a5-ca39580083f9",
   "metadata": {},
   "source": [
    "## NN building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89256f26-0fbb-4a7d-86cd-b4de464214bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "l = nn.Linear(2,5)\n",
    "v = torch.FloatTensor([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e3894895-c78c-4a8e-ac94-6890baad4543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.4305, -0.3858,  1.1154,  0.3309,  0.2852], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b9daa3c-d816-4106-acb8-a7aefcb78750",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nn.Sequential(\n",
    "    nn.Linear(2,5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5, 20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05d7ce94-751c-406e-b73f-356864fd244d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=5, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=5, out_features=20, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (5): Dropout(p=0.3, inplace=False)\n",
       "  (6): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fcfd826c-7986-401c-bf53-189a52afa2f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1113, 0.0999, 0.0765, 0.1350, 0.0855, 0.0946, 0.0823, 0.0953, 0.1118,\n",
       "         0.1077]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s(torch.FloatTensor([[1,2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e494df-f001-424f-aa33-4b1c867eb6b0",
   "metadata": {},
   "source": [
    "## Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "78d04c29-caad-4cea-a1e3-3bfd1537b07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurModule(nn.Module):\n",
    "    def __init__(self, num_inputs, num_classes, dropout_prob = 0.3):\n",
    "        super(OurModule, self).__init__()\n",
    "        self.pipe = nn.Sequential(\n",
    "            nn.Linear(num_inputs, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(5, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, num_classes),\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Softmax(dim=1)\n",
    "        ) # register module\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de48f488-7739-4d36-9c1a-338b56f95b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OurModule(\n",
      "  (pipe): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "tensor([[0.4216, 0.2826, 0.2958]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "net = OurModule(num_inputs=2, num_classes=3)\n",
    "v = torch.FloatTensor([[2,3]])\n",
    "out = net(v)\n",
    "print(net)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6287a440-4721-4f53-99bc-d3fbd8fcb490",
   "metadata": {},
   "source": [
    "## Monitoring with TensorBoard         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e2be6ff-b9b5-41a4-91bb-9238b1b0cc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "217b548c-cabb-4aed-8ade-fc7ee84cecc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "funcs = {\"sin\": math.sin, \"cos\":math.cos, \"tan\":math.tan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3efb680-914f-4230-9836-662697ed6f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "for angle in range(-360, 360):\n",
    "    angle_rad= angle*math.pi / 180\n",
    "    for name, fun in funcs.items():\n",
    "        val= fun(angle_rad)\n",
    "        writer.add_scalar(name, val, angle)\n",
    "        \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae2392-1b68-495d-8a5a-0104f1550154",
   "metadata": {},
   "source": [
    "## GAN on Atari images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "29039bd2-91e8-413f-abdb-a7ee619a6526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import gym\n",
    "import gym.spaces\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "log = gym.logger\n",
    "log.set_level(gym.logger.INFO)\n",
    "\n",
    "LATENT_VECTOR_SIZE = 100 # same as codings_size\n",
    "DISCR_FILTERS = 64\n",
    "GENER_FILTERS = 64\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# dimension input image will be rescaled\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "LEARNING_RATE = 0.0001\n",
    "REPORT_EVERY_ITER = 100\n",
    "SAVE_IMAGE_EVERY_ITER = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da547e70-e343-4474-97d7-cb4ad9b8d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputWrapper(gym.ObservationWrapper): # wrapper for vanilla env\n",
    "    def __init__(self, *args):\n",
    "        super(InputWrapper, self).__init__(*args) # env goes in here?\n",
    "        assert isinstance(self.observation_space, gym.spaces.Box) # check whether is observation is box\n",
    "        old_space = self.observation_space\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            self.observation(old_space.low),\n",
    "            self.observation(old_space.high), # what?\n",
    "            dtype = np.float32)\n",
    "        pass\n",
    "    \n",
    "    def observation(self, observation):\n",
    "        new_obs = cv2.resize(\n",
    "            observation, (IMAGE_SIZE, IMAGE_SIZE))\n",
    "        new_obs = np.moveaxis(new_obs, 2,0) # from (210,160,3) to (3, 160, 210)\n",
    "        return new_obs.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "12a2c9d7-1ee3-4fc6-bbc7-5be4e8c06224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module): # nn.Module !!\n",
    "    def __init__(self, input_shape): # takes input shape as argument\n",
    "        super(Discriminator, self).__init__()\n",
    "        # this pipe converges image into the single number\n",
    "        self.conv_pipe = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape[0], out_channels=DISCR_FILTERS,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS, out_channels=DISCR_FILTERS*2,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(DISCR_FILTERS*2), # batch norm 2d!\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS * 2, out_channels=DISCR_FILTERS * 4,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(DISCR_FILTERS * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS * 4, out_channels=DISCR_FILTERS * 8,\n",
    "                      kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(DISCR_FILTERS * 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=DISCR_FILTERS * 8, out_channels=1, # to one!\n",
    "                      kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv_pipe(x)\n",
    "        return conv_out.view(-1, 1).squeeze(dim=1) # what does view do? -> same as reshape but only view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2636f40c-c668-4598-b53c-7cbf9813d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, output_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        # pipe deconvolves input vector into (3, 64, 64) image\n",
    "        self.pipe = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=LATENT_VECTOR_SIZE, out_channels=GENER_FILTERS * 8,\n",
    "                               kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(GENER_FILTERS * 8),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS * 8, out_channels=GENER_FILTERS * 4,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(GENER_FILTERS * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS * 4, out_channels=GENER_FILTERS * 2,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(GENER_FILTERS * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS * 2, out_channels=GENER_FILTERS,\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(GENER_FILTERS),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=GENER_FILTERS, out_channels=output_shape[0],\n",
    "                               kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pipe(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6accffb5-c43e-45dd-8584-f48720f8f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(envs, batch_size = BATCH_SIZE):\n",
    "    batch = [e.reset() for e in envs]\n",
    "    env_gen = iter(lambda: random.choice(envs), None)\n",
    "    \n",
    "    while(True):\n",
    "        e = next(env_gen) # get next env as random\n",
    "        obs, reward, is_done, _ = e.step(e.action_space.sample())\n",
    "        if(np.mean(obs) > 0.01):\n",
    "            batch.append(obs)\n",
    "        if len(batch) == batch_size:\n",
    "            # normalize input!\n",
    "            batch_np = np.array(batch, dtype=np.float32)\n",
    "            batch_np = batch_np * (2.0 / 255.0 ) - 1.0\n",
    "            yield torch.tensor(batch_np) # return batch as soon as it's made\n",
    "            batch.clear() # do not end here -> make a endless generator\n",
    "        if is_done:\n",
    "            e.reset()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e1a2ace-64a4-4ed9-9fa2-3e3f9fc59ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Making new env: Breakout-v0\n",
      "INFO: Making new env: AirRaid-v0\n",
      "INFO: Making new env: Pong-v0\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "device = torch.device(\"cuda\")\n",
    "envs = [\n",
    "    InputWrapper(gym.make(name)) for name in (\"Breakout-v0\", \"AirRaid-v0\", \"Pong-v0\")\n",
    "]\n",
    "\n",
    "input_shape = envs[0].observation_space.shape\n",
    "\n",
    "net_discr = Discriminator(input_shape=input_shape).to(device) # because it inherits NN.module\n",
    "net_gener = Generator(output_shape=input_shape).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c46b5156-f048-4765-ac31-c2dea749e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = nn.BCELoss() # pixelwise loss\n",
    "gen_optimizer = optim.Adam(\n",
    "    params = net_gener.parameters(), lr = LEARNING_RATE,\n",
    "    betas = (0.5, 0.999)) # the exponential decay params\n",
    "dis_optimizer = optim.Adam(\n",
    "    params = net_discr.parameters(), lr = LEARNING_RATE,\n",
    "    betas = (0.5, 0.999))\n",
    "writer =  SummaryWriter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acc26aab-36f2-4f83-9d93-2f204425a43f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Iter 100: gen_loss=6.912e+00, dis_loss=8.432e-03\n",
      "INFO: Iter 200: gen_loss=7.466e+00, dis_loss=2.898e-03\n",
      "INFO: Iter 300: gen_loss=7.610e+00, dis_loss=1.723e-03\n",
      "INFO: Iter 400: gen_loss=7.529e+00, dis_loss=1.398e-01\n",
      "INFO: Iter 500: gen_loss=7.105e+00, dis_loss=9.364e-03\n",
      "INFO: Iter 600: gen_loss=8.430e+00, dis_loss=4.214e-02\n",
      "INFO: Iter 700: gen_loss=7.156e+00, dis_loss=1.220e-02\n",
      "INFO: Iter 800: gen_loss=7.387e+00, dis_loss=3.086e-03\n",
      "INFO: Iter 900: gen_loss=7.114e+00, dis_loss=3.681e-03\n",
      "INFO: Iter 1000: gen_loss=7.358e+00, dis_loss=1.945e-03\n",
      "INFO: Iter 1100: gen_loss=7.759e+00, dis_loss=1.433e-03\n",
      "INFO: Iter 1200: gen_loss=9.129e+00, dis_loss=2.893e-02\n",
      "INFO: Iter 1300: gen_loss=7.272e+00, dis_loss=7.217e-02\n",
      "INFO: Iter 1400: gen_loss=5.934e+00, dis_loss=2.176e-02\n",
      "INFO: Iter 1500: gen_loss=7.745e+00, dis_loss=1.376e-01\n",
      "INFO: Iter 1600: gen_loss=5.647e+00, dis_loss=3.749e-01\n",
      "INFO: Iter 1700: gen_loss=5.684e+00, dis_loss=3.101e-01\n",
      "INFO: Iter 1800: gen_loss=4.140e+00, dis_loss=3.393e-01\n",
      "INFO: Iter 1900: gen_loss=4.395e+00, dis_loss=2.889e-01\n",
      "INFO: Iter 2000: gen_loss=5.492e+00, dis_loss=1.082e-01\n",
      "INFO: Iter 2100: gen_loss=5.168e+00, dis_loss=2.309e-01\n",
      "INFO: Iter 2200: gen_loss=4.396e+00, dis_loss=2.568e-01\n",
      "INFO: Iter 2300: gen_loss=6.415e+00, dis_loss=6.530e-02\n",
      "INFO: Iter 2400: gen_loss=5.723e+00, dis_loss=1.143e-01\n",
      "INFO: Iter 2500: gen_loss=7.126e+00, dis_loss=1.862e-02\n",
      "INFO: Iter 2600: gen_loss=6.724e+00, dis_loss=1.670e-01\n",
      "INFO: Iter 2700: gen_loss=6.484e+00, dis_loss=6.132e-02\n",
      "INFO: Iter 2800: gen_loss=6.761e+00, dis_loss=9.603e-02\n",
      "INFO: Iter 2900: gen_loss=6.873e+00, dis_loss=9.608e-02\n",
      "INFO: Iter 3000: gen_loss=7.596e+00, dis_loss=8.981e-03\n",
      "INFO: Iter 3100: gen_loss=8.308e+00, dis_loss=1.781e-02\n",
      "INFO: Iter 3200: gen_loss=8.482e+00, dis_loss=2.668e-02\n",
      "INFO: Iter 3300: gen_loss=5.741e+00, dis_loss=2.447e-01\n",
      "INFO: Iter 3400: gen_loss=7.617e+00, dis_loss=7.356e-02\n",
      "INFO: Iter 3500: gen_loss=6.918e+00, dis_loss=6.697e-02\n",
      "INFO: Iter 3600: gen_loss=7.356e+00, dis_loss=6.564e-02\n",
      "INFO: Iter 3700: gen_loss=8.453e+00, dis_loss=1.309e-02\n",
      "INFO: Iter 3800: gen_loss=8.649e+00, dis_loss=5.095e-03\n",
      "INFO: Iter 3900: gen_loss=5.559e+00, dis_loss=2.678e-01\n",
      "INFO: Iter 4000: gen_loss=7.662e+00, dis_loss=9.236e-03\n",
      "INFO: Iter 4100: gen_loss=8.042e+00, dis_loss=5.111e-03\n",
      "INFO: Iter 4200: gen_loss=7.478e+00, dis_loss=1.218e-01\n",
      "INFO: Iter 4300: gen_loss=7.130e+00, dis_loss=1.576e-02\n",
      "INFO: Iter 4400: gen_loss=8.351e+00, dis_loss=7.559e-03\n",
      "INFO: Iter 4500: gen_loss=8.633e+00, dis_loss=1.304e-02\n",
      "INFO: Iter 4600: gen_loss=7.910e+00, dis_loss=1.322e-01\n",
      "INFO: Iter 4700: gen_loss=6.792e+00, dis_loss=1.191e-01\n",
      "INFO: Iter 4800: gen_loss=7.579e+00, dis_loss=1.836e-01\n",
      "INFO: Iter 4900: gen_loss=6.063e+00, dis_loss=1.434e-01\n",
      "INFO: Iter 5000: gen_loss=6.192e+00, dis_loss=1.335e-01\n",
      "INFO: Iter 5100: gen_loss=7.283e+00, dis_loss=9.102e-03\n",
      "INFO: Iter 5200: gen_loss=6.512e+00, dis_loss=1.314e-01\n",
      "INFO: Iter 5300: gen_loss=7.665e+00, dis_loss=1.464e-02\n",
      "INFO: Iter 5400: gen_loss=8.797e+00, dis_loss=6.919e-03\n",
      "INFO: Iter 5500: gen_loss=6.474e+00, dis_loss=3.333e-01\n",
      "INFO: Iter 5600: gen_loss=7.355e+00, dis_loss=9.537e-03\n",
      "INFO: Iter 5700: gen_loss=8.609e+00, dis_loss=4.895e-03\n",
      "INFO: Iter 5800: gen_loss=8.568e+00, dis_loss=6.003e-03\n",
      "INFO: Iter 5900: gen_loss=6.282e+00, dis_loss=3.749e-01\n",
      "INFO: Iter 6000: gen_loss=7.082e+00, dis_loss=3.400e-02\n",
      "INFO: Iter 6100: gen_loss=6.224e+00, dis_loss=1.236e-01\n",
      "INFO: Iter 6200: gen_loss=8.327e+00, dis_loss=7.848e-03\n",
      "INFO: Iter 6300: gen_loss=9.161e+00, dis_loss=1.090e-02\n",
      "INFO: Iter 6400: gen_loss=8.554e+00, dis_loss=1.379e-02\n",
      "INFO: Iter 6500: gen_loss=9.352e+00, dis_loss=3.499e-03\n",
      "INFO: Iter 6600: gen_loss=8.921e+00, dis_loss=3.757e-03\n",
      "INFO: Iter 6700: gen_loss=9.662e+00, dis_loss=3.369e-03\n",
      "INFO: Iter 6800: gen_loss=7.607e+00, dis_loss=1.769e-01\n",
      "INFO: Iter 6900: gen_loss=7.951e+00, dis_loss=1.707e-02\n",
      "INFO: Iter 7000: gen_loss=8.321e+00, dis_loss=2.137e-01\n",
      "INFO: Iter 7100: gen_loss=5.971e+00, dis_loss=8.719e-02\n",
      "INFO: Iter 7200: gen_loss=7.051e+00, dis_loss=3.730e-02\n",
      "INFO: Iter 7300: gen_loss=6.410e+00, dis_loss=1.964e-01\n",
      "INFO: Iter 7400: gen_loss=6.300e+00, dis_loss=1.571e-01\n",
      "INFO: Iter 7500: gen_loss=8.122e+00, dis_loss=1.953e-01\n",
      "INFO: Iter 7600: gen_loss=6.956e+00, dis_loss=1.450e-01\n",
      "INFO: Iter 7700: gen_loss=6.369e+00, dis_loss=2.402e-01\n",
      "INFO: Iter 7800: gen_loss=5.857e+00, dis_loss=2.265e-01\n",
      "INFO: Iter 7900: gen_loss=5.888e+00, dis_loss=1.139e-01\n",
      "INFO: Iter 8000: gen_loss=5.675e+00, dis_loss=2.649e-01\n",
      "INFO: Iter 8100: gen_loss=6.722e+00, dis_loss=3.073e-02\n",
      "INFO: Iter 8200: gen_loss=6.583e+00, dis_loss=2.202e-01\n",
      "INFO: Iter 8300: gen_loss=5.512e+00, dis_loss=2.569e-01\n",
      "INFO: Iter 8400: gen_loss=5.207e+00, dis_loss=2.925e-01\n",
      "INFO: Iter 8500: gen_loss=5.317e+00, dis_loss=2.499e-01\n",
      "INFO: Iter 8600: gen_loss=6.677e+00, dis_loss=2.465e-02\n",
      "INFO: Iter 8700: gen_loss=6.374e+00, dis_loss=1.151e-02\n",
      "INFO: Iter 8800: gen_loss=6.928e+00, dis_loss=8.256e-03\n",
      "INFO: Iter 8900: gen_loss=7.216e+00, dis_loss=4.688e-03\n",
      "INFO: Iter 9000: gen_loss=6.467e+00, dis_loss=5.179e-03\n",
      "INFO: Iter 9100: gen_loss=6.695e+00, dis_loss=3.461e-03\n",
      "INFO: Iter 9200: gen_loss=6.550e+00, dis_loss=5.491e-03\n",
      "INFO: Iter 9300: gen_loss=7.456e+00, dis_loss=4.343e-03\n",
      "INFO: Iter 9400: gen_loss=6.881e+00, dis_loss=3.772e-01\n",
      "INFO: Iter 9500: gen_loss=7.761e+00, dis_loss=4.901e-02\n",
      "INFO: Iter 9600: gen_loss=9.759e+00, dis_loss=1.670e-02\n",
      "INFO: Iter 9700: gen_loss=9.030e+00, dis_loss=1.840e-01\n",
      "INFO: Iter 9800: gen_loss=7.491e+00, dis_loss=9.238e-02\n",
      "INFO: Iter 9900: gen_loss=8.371e+00, dis_loss=7.596e-03\n",
      "INFO: Iter 10000: gen_loss=7.103e+00, dis_loss=1.457e-02\n",
      "INFO: Iter 10100: gen_loss=7.543e+00, dis_loss=3.657e-02\n",
      "INFO: Iter 10200: gen_loss=7.719e+00, dis_loss=6.542e-02\n",
      "INFO: Iter 10300: gen_loss=6.882e+00, dis_loss=1.133e-02\n",
      "INFO: Iter 10400: gen_loss=8.702e+00, dis_loss=3.066e-02\n",
      "INFO: Iter 10500: gen_loss=8.243e+00, dis_loss=4.069e-02\n",
      "INFO: Iter 10600: gen_loss=9.054e+00, dis_loss=1.758e-02\n",
      "INFO: Iter 10700: gen_loss=8.581e+00, dis_loss=8.347e-02\n",
      "INFO: Iter 10800: gen_loss=8.249e+00, dis_loss=1.118e-01\n",
      "INFO: Iter 10900: gen_loss=7.109e+00, dis_loss=8.333e-03\n",
      "INFO: Iter 11000: gen_loss=6.891e+00, dis_loss=2.378e-02\n",
      "INFO: Iter 11100: gen_loss=7.894e+00, dis_loss=3.897e-02\n",
      "INFO: Iter 11200: gen_loss=8.258e+00, dis_loss=2.596e-02\n",
      "INFO: Iter 11300: gen_loss=9.120e+00, dis_loss=6.413e-02\n",
      "INFO: Iter 11400: gen_loss=8.337e+00, dis_loss=1.623e-02\n",
      "INFO: Iter 11500: gen_loss=8.416e+00, dis_loss=1.732e-01\n",
      "INFO: Iter 11600: gen_loss=7.062e+00, dis_loss=1.312e-01\n",
      "INFO: Iter 11700: gen_loss=8.489e+00, dis_loss=3.979e-02\n",
      "INFO: Iter 11800: gen_loss=7.656e+00, dis_loss=1.171e-02\n",
      "INFO: Iter 11900: gen_loss=8.417e+00, dis_loss=1.056e-02\n",
      "INFO: Iter 12000: gen_loss=5.685e+00, dis_loss=2.870e-01\n",
      "INFO: Iter 12100: gen_loss=7.469e+00, dis_loss=1.877e-02\n",
      "INFO: Iter 12200: gen_loss=8.084e+00, dis_loss=1.848e-02\n",
      "INFO: Iter 12300: gen_loss=8.570e+00, dis_loss=4.089e-03\n",
      "INFO: Iter 12400: gen_loss=9.015e+00, dis_loss=3.551e-03\n",
      "INFO: Iter 12500: gen_loss=8.625e+00, dis_loss=1.417e-01\n",
      "INFO: Iter 12600: gen_loss=7.399e+00, dis_loss=2.268e-01\n",
      "INFO: Iter 12700: gen_loss=7.681e+00, dis_loss=4.550e-02\n",
      "INFO: Iter 12800: gen_loss=8.374e+00, dis_loss=3.643e-02\n",
      "INFO: Iter 12900: gen_loss=6.764e+00, dis_loss=1.413e-01\n",
      "INFO: Iter 13000: gen_loss=8.182e+00, dis_loss=1.079e-01\n",
      "INFO: Iter 13100: gen_loss=7.562e+00, dis_loss=2.034e-01\n",
      "INFO: Iter 13200: gen_loss=7.662e+00, dis_loss=1.546e-02\n",
      "INFO: Iter 13300: gen_loss=8.337e+00, dis_loss=1.025e-02\n",
      "INFO: Iter 13400: gen_loss=8.330e+00, dis_loss=3.357e-02\n",
      "INFO: Iter 13500: gen_loss=9.594e+00, dis_loss=1.569e-02\n",
      "INFO: Iter 13600: gen_loss=1.045e+01, dis_loss=3.039e-03\n",
      "INFO: Iter 13700: gen_loss=6.863e+00, dis_loss=1.146e-01\n",
      "INFO: Iter 13800: gen_loss=8.081e+00, dis_loss=1.655e-01\n",
      "INFO: Iter 13900: gen_loss=8.637e+00, dis_loss=6.733e-03\n",
      "INFO: Iter 14000: gen_loss=1.013e+01, dis_loss=1.582e-02\n",
      "INFO: Iter 14100: gen_loss=9.102e+00, dis_loss=2.847e-01\n",
      "INFO: Iter 14200: gen_loss=8.486e+00, dis_loss=1.059e-02\n",
      "INFO: Iter 14300: gen_loss=8.233e+00, dis_loss=1.757e-01\n",
      "INFO: Iter 14400: gen_loss=7.933e+00, dis_loss=2.001e-01\n",
      "INFO: Iter 14500: gen_loss=6.996e+00, dis_loss=2.025e-01\n",
      "INFO: Iter 14600: gen_loss=7.285e+00, dis_loss=1.866e-01\n",
      "INFO: Iter 14700: gen_loss=7.416e+00, dis_loss=1.782e-01\n",
      "INFO: Iter 14800: gen_loss=7.332e+00, dis_loss=2.709e-02\n",
      "INFO: Iter 14900: gen_loss=5.796e+00, dis_loss=4.170e-01\n",
      "INFO: Iter 15000: gen_loss=6.328e+00, dis_loss=4.218e-02\n",
      "INFO: Iter 15100: gen_loss=6.259e+00, dis_loss=2.002e-01\n",
      "INFO: Iter 15200: gen_loss=6.741e+00, dis_loss=1.107e-01\n",
      "INFO: Iter 15300: gen_loss=5.520e+00, dis_loss=2.188e-01\n",
      "INFO: Iter 15400: gen_loss=6.714e+00, dis_loss=9.517e-02\n",
      "INFO: Iter 15500: gen_loss=7.268e+00, dis_loss=4.164e-02\n",
      "INFO: Iter 15600: gen_loss=7.960e+00, dis_loss=1.564e-01\n",
      "INFO: Iter 15700: gen_loss=6.795e+00, dis_loss=1.645e-01\n",
      "INFO: Iter 15800: gen_loss=6.525e+00, dis_loss=1.776e-01\n",
      "INFO: Iter 15900: gen_loss=7.080e+00, dis_loss=1.920e-02\n",
      "INFO: Iter 16000: gen_loss=6.970e+00, dis_loss=1.937e-01\n",
      "INFO: Iter 16100: gen_loss=6.882e+00, dis_loss=1.050e-01\n",
      "INFO: Iter 16200: gen_loss=7.065e+00, dis_loss=1.790e-01\n",
      "INFO: Iter 16300: gen_loss=5.895e+00, dis_loss=5.152e-02\n",
      "INFO: Iter 16400: gen_loss=7.764e+00, dis_loss=1.320e-02\n",
      "INFO: Iter 16500: gen_loss=8.124e+00, dis_loss=1.265e-01\n",
      "INFO: Iter 16600: gen_loss=5.346e+00, dis_loss=2.113e-01\n",
      "INFO: Iter 16700: gen_loss=7.192e+00, dis_loss=1.995e-01\n",
      "INFO: Iter 16800: gen_loss=6.577e+00, dis_loss=8.353e-02\n",
      "INFO: Iter 16900: gen_loss=6.987e+00, dis_loss=2.072e-01\n",
      "INFO: Iter 17000: gen_loss=7.476e+00, dis_loss=4.564e-02\n",
      "INFO: Iter 17100: gen_loss=8.317e+00, dis_loss=1.399e-01\n",
      "INFO: Iter 17200: gen_loss=6.109e+00, dis_loss=2.397e-01\n",
      "INFO: Iter 17300: gen_loss=6.618e+00, dis_loss=4.543e-02\n",
      "INFO: Iter 17400: gen_loss=7.445e+00, dis_loss=7.223e-02\n",
      "INFO: Iter 17500: gen_loss=7.086e+00, dis_loss=6.181e-02\n",
      "INFO: Iter 17600: gen_loss=7.604e+00, dis_loss=2.359e-01\n",
      "INFO: Iter 17700: gen_loss=6.805e+00, dis_loss=9.871e-02\n",
      "INFO: Iter 17800: gen_loss=6.539e+00, dis_loss=1.372e-02\n",
      "INFO: Iter 17900: gen_loss=7.384e+00, dis_loss=7.527e-03\n",
      "INFO: Iter 18000: gen_loss=7.218e+00, dis_loss=5.440e-03\n",
      "INFO: Iter 18100: gen_loss=8.310e+00, dis_loss=7.470e-03\n",
      "INFO: Iter 18200: gen_loss=9.133e+00, dis_loss=2.970e-03\n",
      "INFO: Iter 18300: gen_loss=9.068e+00, dis_loss=2.039e-02\n",
      "INFO: Iter 18400: gen_loss=7.828e+00, dis_loss=5.499e-03\n",
      "INFO: Iter 18500: gen_loss=6.471e+00, dis_loss=5.257e-03\n",
      "INFO: Iter 18600: gen_loss=7.200e+00, dis_loss=3.065e-03\n",
      "INFO: Iter 18700: gen_loss=7.610e+00, dis_loss=1.791e-03\n",
      "INFO: Iter 18800: gen_loss=7.899e+00, dis_loss=1.683e-03\n",
      "INFO: Iter 18900: gen_loss=7.851e+00, dis_loss=1.025e-03\n",
      "INFO: Iter 19000: gen_loss=8.038e+00, dis_loss=1.138e-03\n",
      "INFO: Iter 19100: gen_loss=8.125e+00, dis_loss=9.593e-04\n",
      "INFO: Iter 19200: gen_loss=8.438e+00, dis_loss=7.308e-04\n",
      "INFO: Iter 19300: gen_loss=8.758e+00, dis_loss=6.877e-04\n",
      "INFO: Iter 19400: gen_loss=8.718e+00, dis_loss=7.596e-04\n",
      "INFO: Iter 19500: gen_loss=9.221e+00, dis_loss=3.264e-04\n",
      "INFO: Iter 19600: gen_loss=9.306e+00, dis_loss=3.558e-04\n",
      "INFO: Iter 19700: gen_loss=9.475e+00, dis_loss=4.185e-04\n",
      "INFO: Iter 19800: gen_loss=9.575e+00, dis_loss=2.948e-04\n",
      "INFO: Iter 19900: gen_loss=9.803e+00, dis_loss=2.610e-04\n",
      "INFO: Iter 20000: gen_loss=9.807e+00, dis_loss=2.874e-04\n",
      "INFO: Iter 20100: gen_loss=1.005e+01, dis_loss=1.892e-04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_100216/174566248.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfake_labels_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mbatch_v\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# gen input is 4d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgen_input_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLATENT_VECTOR_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_100216/1055070171.py\u001b[0m in \u001b[0;36miterate_batches\u001b[0;34m(envs, batch_size)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_gen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get next env as random\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DRLH/lib/python3.7/site-packages/gym/core.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DRLH/lib/python3.7/site-packages/gym/wrappers/time_limit.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Cannot call env.step() before calling reset()\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elapsed_steps\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_episode_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DRLH/lib/python3.7/site-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, a)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame_over\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"ale.lives\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DRLH/lib/python3.7/site-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36m_get_obs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_ram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obs_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'image'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DRLH/lib/python3.7/site-packages/gym/envs/atari/atari_env.py\u001b[0m in \u001b[0;36m_get_image\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetScreenRGB2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/DRLH/lib/python3.7/site-packages/atari_py/ale_python_interface.py\u001b[0m in \u001b[0;36mgetScreenRGB2\u001b[0;34m(self, screen_data)\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mscreen_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mscreen_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0male_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetScreenRGB2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ctypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscreen_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gen_losses = []\n",
    "dis_losses = []\n",
    "iter_no = 0\n",
    "\n",
    "true_labels_v = torch.ones(BATCH_SIZE, device=device)\n",
    "fake_labels_v = torch.zeros(BATCH_SIZE, device=device)\n",
    "\n",
    "for batch_v in iterate_batches(envs):\n",
    "    # gen input is 4d\n",
    "    gen_input_v = torch.FloatTensor(BATCH_SIZE, LATENT_VECTOR_SIZE, 1,1)\n",
    "    gen_input_v.normal_(0,1)\n",
    "    gen_input_v = gen_input_v.to(device)\n",
    "    batch_v = batch_v.to(device)\n",
    "    gen_output_v = net_gener(gen_input_v)\n",
    "    \n",
    "    dis_optimizer.zero_grad()\n",
    "    dis_output_true_v = net_discr(batch_v)\n",
    "    dis_output_fake_v = net_discr(gen_output_v.detach()) # calling detach here stopps the gradient from flowing!\n",
    "    \n",
    "    dis_loss = objective(dis_output_fake_v, fake_labels_v) + objective(dis_output_true_v, true_labels_v)\n",
    "    dis_loss.backward()\n",
    "    dis_optimizer.step()\n",
    "    dis_losses.append(dis_loss.item())  # call a value from 0d tensor\n",
    "    \n",
    "    \n",
    "    gen_optimizer.zero_grad()\n",
    "    dis_output_v = net_discr(gen_output_v) # no not call detach here because we need the gradients\n",
    "    gen_loss_v = objective(dis_output_v, true_labels_v)\n",
    "    gen_loss_v.backward()\n",
    "    gen_optimizer.step()\n",
    "    gen_losses.append(gen_loss_v.item())    \n",
    "    \n",
    "    iter_no += 1\n",
    "    if iter_no % REPORT_EVERY_ITER == 0:\n",
    "        log.info(\"Iter %d: gen_loss=%.3e, dis_loss=%.3e\", iter_no, np.mean(gen_losses), np.mean(dis_losses))\n",
    "        \n",
    "        writer.add_scalar(\"gen_loss\", np.mean(gen_losses), iter_no),\n",
    "        writer.add_scalar(\"dis_loss\", np.mean(dis_losses), iter_no)\n",
    "        gen_losses = []\n",
    "        dis_losses = [] # clear list\n",
    "        \n",
    "    if iter_no % SAVE_IMAGE_EVERY_ITER == 0:\n",
    "        writer.add_image(\"fake\", vutils.make_grid(\n",
    "            gen_output_v.data[:64], normalize=True), iter_no)\n",
    "        writer.add_image(\"real\", vutils.make_grid(\n",
    "            batch_v.data[:64], normalize=True), iter_no)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fd4124-dade-4e51-bca5-7d39c3f137e3",
   "metadata": {},
   "source": [
    "## PyTorch Ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "87881843-bd2e-4b8b-9a83-f10916a1fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import RunningAverage\n",
    "from ignite.contrib.handlers import tensorboard_logger as tb_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f3d2d504-873f-406e-bb6d-25e676cae3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_discr = Discriminator(input_shape=input_shape).to(device)\n",
    "net_gener = Generator(output_shape=input_shape).to(device)\n",
    "gen_optimizer = optim.Adam(params=net_gener.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
    "dis_optimizer = optim.Adam(params=net_discr.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "59c70600-a653-4e7e-9cfd-3275fcd2a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_v = torch.ones(BATCH_SIZE, device=device)\n",
    "fake_labels_v = torch.zeros(BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f1838b47-0e24-4ba9-bc04-ee56c60b9d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_batch(trainer, batch): # a function to input into engine\n",
    "    gen_input_v = torch.FloatTensor(BATCH_SIZE, LATENT_VECTOR_SIZE, 1, 1)\n",
    "    gen_input_v.normal_(0,1)\n",
    "    gen_input_v = gen_input_v.to(device)\n",
    "    \n",
    "    batch_v = batch.to(device)\n",
    "    \n",
    "    gen_output_v = net_gener(gen_input_v)\n",
    "    \n",
    "    # train discriptor\n",
    "    dis_optimizer.zero_grad()\n",
    "    dis_output_true_v = net_discr(batch_v)\n",
    "    dis_output_fake_v = net_discr(gen_output_v.detach())\n",
    "    dis_loss = objective(dis_output_fake_v, fake_labels_v) + objective(dis_output_true_v, true_labels_v)\n",
    "    dis_loss.backward()\n",
    "    dis_optimizer.step()\n",
    "    \n",
    "    # train generator\n",
    "    gen_optimizer.zero_grad()\n",
    "    dis_output_v = net_discr(gen_output_v)\n",
    "    gen_loss = objective(dis_output_v, true_labels_v)\n",
    "    gen_loss.backward()\n",
    "    gen_optimizer.step()\n",
    "    \n",
    "    if trainer.state.iteration % SAVE_IMAGE_EVERY_ITER == 0:\n",
    "        fake_img = vutils.make_grid(gen_output_v.data[:64], normalize=True)\n",
    "        trainer.tb.writer.add_image(\"fake\", fake_img, trainer.state.iteration)\n",
    "        real_img = vutils.make_grid(batch_v.data[:64], normalize=True)\n",
    "        trainer.tb.writer.add_image(\"real\", real_img, trainer.state.iteration)\n",
    "        trainer.tb.writer.flush() # use flush!\n",
    "        \n",
    "    return dis_loss.item(), gen_loss.item() # return train results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "02433b6b-c0d3-46a9-ab11-6f10fc054631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x7f3265c5ec88>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = Engine(process_batch) # attach our train function here!\n",
    "tb = tb_logger.TensorboardLogger(log_dir=None) # where?\n",
    "engine.tb = tb # save module like this\n",
    "RunningAverage(output_transform=lambda out: out[1]).attach(engine, \"avg_loss_gen\") # attach metrics -> how?\n",
    "RunningAverage(output_transform=lambda out: out[0]).attach(engine, \"avg_loss_dis\")\n",
    "\n",
    "handler = tb_logger.OutputHandler(tag=\"train\", metric_names=[\"avg_loss_gen\", \"avg_loss_dis\"])\n",
    "tb.attach(engine, log_handler=handler, event_name=Events.ITERATION_COMPLETED) # attach logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31aaeb5c-d915-498b-a8cb-a31f290f9090",
   "metadata": {},
   "outputs": [],
   "source": [
    "@engine.on(Events.ITERATION_COMPLETED)\n",
    "def log_losses(trainer):\n",
    "    if trainer.state.iteration % REPORT_EVERY_ITER == 0:\n",
    "        log.info(\"%d: gen_loss=%f, dis_loss=%f\",\n",
    "                 trainer.state.iteration,\n",
    "                 trainer.state.metrics[\"avg_loss_gen\"],\n",
    "                 trainer.state.metrics[\"avg_loss_dis\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1f630e-da0e-45c0-a70f-ea1a8f8270f3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 100: gen_loss=5.345626, dis_loss=0.113565\n",
      "INFO: 200: gen_loss=6.632696, dis_loss=0.019313\n",
      "INFO: 300: gen_loss=7.193804, dis_loss=0.005108\n",
      "INFO: 400: gen_loss=7.378413, dis_loss=0.002513\n",
      "INFO: 500: gen_loss=7.750945, dis_loss=0.001690\n",
      "INFO: 600: gen_loss=8.026420, dis_loss=0.001059\n",
      "INFO: 700: gen_loss=8.222263, dis_loss=0.001084\n",
      "INFO: 800: gen_loss=8.064052, dis_loss=0.239881\n",
      "INFO: 900: gen_loss=6.484239, dis_loss=0.048323\n",
      "INFO: 1000: gen_loss=5.760964, dis_loss=0.087028\n",
      "INFO: 1100: gen_loss=6.106640, dis_loss=0.020134\n",
      "INFO: 1200: gen_loss=6.309183, dis_loss=0.007554\n",
      "INFO: 1300: gen_loss=6.539118, dis_loss=0.004120\n",
      "INFO: 1400: gen_loss=6.629929, dis_loss=0.003528\n",
      "INFO: 1500: gen_loss=6.843645, dis_loss=0.003711\n",
      "INFO: 1600: gen_loss=7.151535, dis_loss=0.003226\n",
      "INFO: 1700: gen_loss=7.473411, dis_loss=0.001459\n",
      "INFO: 1800: gen_loss=7.777237, dis_loss=0.001007\n",
      "INFO: 1900: gen_loss=7.816696, dis_loss=0.000981\n",
      "INFO: 2000: gen_loss=9.046327, dis_loss=0.043740\n",
      "INFO: 2100: gen_loss=7.076248, dis_loss=0.009943\n",
      "INFO: 2200: gen_loss=6.887323, dis_loss=0.005531\n",
      "INFO: 2300: gen_loss=6.086141, dis_loss=0.064820\n",
      "INFO: 2400: gen_loss=6.341667, dis_loss=0.016372\n",
      "INFO: 2500: gen_loss=7.721636, dis_loss=0.075834\n",
      "INFO: 2600: gen_loss=7.195006, dis_loss=0.023293\n",
      "INFO: 2700: gen_loss=6.894589, dis_loss=0.008886\n",
      "INFO: 2800: gen_loss=6.757423, dis_loss=0.003720\n",
      "INFO: 2900: gen_loss=8.474117, dis_loss=0.147883\n",
      "INFO: 3000: gen_loss=6.645325, dis_loss=0.039060\n",
      "INFO: 3100: gen_loss=6.685961, dis_loss=0.015006\n",
      "INFO: 3200: gen_loss=5.447304, dis_loss=0.320093\n",
      "INFO: 3300: gen_loss=4.951893, dis_loss=0.312190\n",
      "INFO: 3400: gen_loss=4.622859, dis_loss=0.421098\n",
      "INFO: 3500: gen_loss=4.475582, dis_loss=0.363688\n",
      "INFO: 3600: gen_loss=4.796728, dis_loss=0.274674\n",
      "INFO: 3700: gen_loss=5.530082, dis_loss=0.171247\n",
      "INFO: 3800: gen_loss=5.247565, dis_loss=0.198372\n",
      "INFO: 3900: gen_loss=5.400594, dis_loss=0.244368\n",
      "INFO: 4000: gen_loss=5.842919, dis_loss=0.134512\n",
      "INFO: 4100: gen_loss=5.507124, dis_loss=0.111039\n",
      "INFO: 4200: gen_loss=5.537380, dis_loss=0.163397\n",
      "INFO: 4300: gen_loss=5.598265, dis_loss=0.131431\n",
      "INFO: 4400: gen_loss=6.244496, dis_loss=0.103137\n",
      "INFO: 4500: gen_loss=4.401601, dis_loss=0.379492\n",
      "INFO: 4600: gen_loss=5.331572, dis_loss=0.129524\n",
      "INFO: 4700: gen_loss=5.598886, dis_loss=0.121353\n",
      "INFO: 4800: gen_loss=5.948366, dis_loss=0.161059\n",
      "INFO: 4900: gen_loss=7.135271, dis_loss=0.123294\n",
      "INFO: 5000: gen_loss=6.846975, dis_loss=0.032751\n",
      "INFO: 5100: gen_loss=6.420776, dis_loss=0.310334\n",
      "INFO: 5200: gen_loss=5.963019, dis_loss=0.173940\n",
      "INFO: 5300: gen_loss=6.863783, dis_loss=0.159282\n",
      "INFO: 5400: gen_loss=6.346212, dis_loss=0.130216\n",
      "INFO: 5500: gen_loss=6.765814, dis_loss=0.042170\n",
      "INFO: 5600: gen_loss=6.166695, dis_loss=0.092059\n",
      "INFO: 5700: gen_loss=7.265704, dis_loss=0.039490\n",
      "INFO: 5800: gen_loss=8.178127, dis_loss=0.018690\n",
      "INFO: 5900: gen_loss=7.161771, dis_loss=0.058872\n",
      "INFO: 6000: gen_loss=8.103744, dis_loss=0.014086\n",
      "INFO: 6100: gen_loss=8.372225, dis_loss=0.008688\n",
      "INFO: 6200: gen_loss=6.896368, dis_loss=0.152025\n",
      "INFO: 6300: gen_loss=6.890692, dis_loss=0.033068\n",
      "INFO: 6400: gen_loss=6.333808, dis_loss=0.131195\n",
      "INFO: 6500: gen_loss=7.455763, dis_loss=0.048621\n",
      "INFO: 6600: gen_loss=8.225785, dis_loss=0.017200\n",
      "INFO: 6700: gen_loss=8.270359, dis_loss=0.030283\n",
      "INFO: 6800: gen_loss=7.851603, dis_loss=0.052614\n",
      "INFO: 6900: gen_loss=7.910326, dis_loss=0.116945\n",
      "INFO: 7000: gen_loss=6.512096, dis_loss=0.103845\n",
      "INFO: 7100: gen_loss=7.027453, dis_loss=0.160806\n",
      "INFO: 7200: gen_loss=8.221379, dis_loss=0.029800\n",
      "INFO: 7300: gen_loss=9.446103, dis_loss=0.010799\n",
      "INFO: 7400: gen_loss=9.275673, dis_loss=0.006599\n",
      "INFO: 7500: gen_loss=6.550225, dis_loss=0.395561\n",
      "INFO: 7600: gen_loss=7.563423, dis_loss=0.079273\n",
      "INFO: 7700: gen_loss=7.892348, dis_loss=0.018445\n",
      "INFO: 7800: gen_loss=7.916496, dis_loss=0.006519\n",
      "INFO: 7900: gen_loss=8.356199, dis_loss=0.023276\n",
      "INFO: 8000: gen_loss=7.719597, dis_loss=0.223932\n",
      "INFO: 8100: gen_loss=8.137273, dis_loss=0.054211\n",
      "INFO: 8200: gen_loss=9.095178, dis_loss=0.013198\n",
      "INFO: 8300: gen_loss=8.745073, dis_loss=0.113728\n",
      "INFO: 8400: gen_loss=8.471012, dis_loss=0.265229\n",
      "INFO: 8500: gen_loss=7.887591, dis_loss=0.046723\n",
      "INFO: 8600: gen_loss=7.934077, dis_loss=0.153936\n",
      "INFO: 8700: gen_loss=8.208225, dis_loss=0.044286\n",
      "INFO: 8800: gen_loss=8.778475, dis_loss=0.031688\n",
      "INFO: 8900: gen_loss=9.314224, dis_loss=0.011121\n",
      "INFO: 9000: gen_loss=7.118801, dis_loss=0.169689\n",
      "INFO: 9100: gen_loss=6.679742, dis_loss=0.028723\n",
      "INFO: 9200: gen_loss=6.705240, dis_loss=0.009721\n",
      "INFO: 9300: gen_loss=6.751139, dis_loss=0.057999\n",
      "INFO: 9400: gen_loss=6.936767, dis_loss=0.235112\n",
      "INFO: 9500: gen_loss=7.308481, dis_loss=0.172623\n",
      "INFO: 9600: gen_loss=6.277230, dis_loss=0.153710\n",
      "INFO: 9700: gen_loss=7.270381, dis_loss=0.036466\n",
      "INFO: 9800: gen_loss=6.994861, dis_loss=0.071611\n",
      "INFO: 9900: gen_loss=6.141557, dis_loss=0.198849\n",
      "INFO: 10000: gen_loss=7.013309, dis_loss=0.139127\n",
      "INFO: 10100: gen_loss=8.024033, dis_loss=0.050403\n",
      "INFO: 10200: gen_loss=7.439682, dis_loss=0.056474\n",
      "INFO: 10300: gen_loss=7.531603, dis_loss=0.029675\n",
      "INFO: 10400: gen_loss=7.814692, dis_loss=0.009818\n",
      "INFO: 10500: gen_loss=7.666514, dis_loss=0.020527\n",
      "INFO: 10600: gen_loss=8.013645, dis_loss=0.092929\n",
      "INFO: 10700: gen_loss=7.847217, dis_loss=0.072626\n",
      "INFO: 10800: gen_loss=9.666652, dis_loss=0.020298\n",
      "INFO: 10900: gen_loss=8.930545, dis_loss=0.005366\n",
      "INFO: 11000: gen_loss=8.215309, dis_loss=0.287557\n",
      "INFO: 11100: gen_loss=7.003644, dis_loss=0.110936\n",
      "INFO: 11200: gen_loss=6.561864, dis_loss=0.089226\n",
      "INFO: 11300: gen_loss=6.973558, dis_loss=0.033478\n",
      "INFO: 11400: gen_loss=7.199896, dis_loss=0.009119\n",
      "INFO: 11500: gen_loss=6.602489, dis_loss=0.184442\n",
      "INFO: 11600: gen_loss=7.130389, dis_loss=0.061908\n",
      "INFO: 11700: gen_loss=6.845785, dis_loss=0.068635\n",
      "INFO: 11800: gen_loss=8.272060, dis_loss=0.031028\n",
      "INFO: 11900: gen_loss=7.512700, dis_loss=0.240191\n",
      "INFO: 12000: gen_loss=6.809579, dis_loss=0.090784\n",
      "INFO: 12100: gen_loss=7.957517, dis_loss=0.076319\n",
      "INFO: 12200: gen_loss=8.274991, dis_loss=0.052876\n",
      "INFO: 12300: gen_loss=8.356697, dis_loss=0.055718\n",
      "INFO: 12400: gen_loss=8.207959, dis_loss=0.018977\n",
      "INFO: 12500: gen_loss=8.850160, dis_loss=0.008360\n",
      "INFO: 12600: gen_loss=6.273020, dis_loss=0.118588\n",
      "INFO: 12700: gen_loss=6.342784, dis_loss=0.019543\n",
      "INFO: 12800: gen_loss=6.659327, dis_loss=0.006443\n",
      "INFO: 12900: gen_loss=7.010916, dis_loss=0.006114\n",
      "INFO: 13000: gen_loss=7.688457, dis_loss=0.004035\n",
      "INFO: 13100: gen_loss=8.339543, dis_loss=0.004299\n",
      "INFO: 13200: gen_loss=8.865948, dis_loss=0.004276\n",
      "INFO: 13300: gen_loss=8.175281, dis_loss=0.037025\n",
      "INFO: 13400: gen_loss=6.486809, dis_loss=0.296698\n",
      "INFO: 13500: gen_loss=6.466611, dis_loss=0.051904\n",
      "INFO: 13600: gen_loss=6.890558, dis_loss=0.082469\n",
      "INFO: 13700: gen_loss=6.550095, dis_loss=0.111252\n",
      "INFO: 13800: gen_loss=7.394503, dis_loss=0.037422\n",
      "INFO: 13900: gen_loss=7.851610, dis_loss=0.020885\n",
      "INFO: 14000: gen_loss=6.826463, dis_loss=0.199908\n",
      "INFO: 14100: gen_loss=7.125191, dis_loss=0.043953\n",
      "INFO: 14200: gen_loss=8.003830, dis_loss=0.009463\n",
      "INFO: 14300: gen_loss=8.117657, dis_loss=0.003893\n",
      "INFO: 14400: gen_loss=8.062887, dis_loss=0.002423\n",
      "INFO: 14500: gen_loss=8.269319, dis_loss=0.002380\n",
      "INFO: 14600: gen_loss=8.073286, dis_loss=0.002451\n",
      "INFO: 14700: gen_loss=7.908613, dis_loss=0.001561\n",
      "INFO: 14800: gen_loss=7.805533, dis_loss=0.041342\n",
      "INFO: 14900: gen_loss=6.898115, dis_loss=0.073173\n",
      "INFO: 15000: gen_loss=7.855322, dis_loss=0.014634\n",
      "INFO: 15100: gen_loss=9.208529, dis_loss=0.027978\n",
      "INFO: 15200: gen_loss=9.848390, dis_loss=0.007988\n",
      "INFO: 15300: gen_loss=6.576676, dis_loss=0.145362\n",
      "INFO: 15400: gen_loss=7.021985, dis_loss=0.039427\n",
      "INFO: 15500: gen_loss=7.421712, dis_loss=0.007737\n",
      "INFO: 15600: gen_loss=8.675935, dis_loss=0.003735\n",
      "INFO: 15700: gen_loss=7.495608, dis_loss=0.019960\n",
      "INFO: 15800: gen_loss=7.086610, dis_loss=0.076761\n",
      "INFO: 15900: gen_loss=7.011679, dis_loss=0.014903\n",
      "INFO: 16000: gen_loss=8.030029, dis_loss=0.005038\n",
      "INFO: 16100: gen_loss=7.573655, dis_loss=0.253282\n",
      "INFO: 16200: gen_loss=6.305377, dis_loss=0.224331\n",
      "INFO: 16300: gen_loss=6.681345, dis_loss=0.067125\n",
      "INFO: 16400: gen_loss=5.873888, dis_loss=0.250943\n",
      "INFO: 16500: gen_loss=5.872897, dis_loss=0.269955\n",
      "INFO: 16600: gen_loss=5.301272, dis_loss=0.242117\n",
      "INFO: 16700: gen_loss=5.719535, dis_loss=0.225741\n",
      "INFO: 16800: gen_loss=7.120954, dis_loss=0.068299\n",
      "INFO: 16900: gen_loss=5.966279, dis_loss=0.144152\n",
      "INFO: 17000: gen_loss=6.675846, dis_loss=0.057604\n",
      "INFO: 17100: gen_loss=7.113487, dis_loss=0.345742\n",
      "INFO: 17200: gen_loss=5.906272, dis_loss=0.087685\n",
      "INFO: 17300: gen_loss=6.061516, dis_loss=0.100191\n",
      "INFO: 17400: gen_loss=5.449835, dis_loss=0.238526\n",
      "INFO: 17500: gen_loss=5.903280, dis_loss=0.159513\n",
      "INFO: 17600: gen_loss=5.693171, dis_loss=0.101508\n",
      "INFO: 17700: gen_loss=5.913330, dis_loss=0.089136\n",
      "INFO: 17800: gen_loss=6.739117, dis_loss=0.050195\n",
      "INFO: 17900: gen_loss=5.361589, dis_loss=0.138714\n",
      "INFO: 18000: gen_loss=6.641982, dis_loss=0.118649\n",
      "INFO: 18100: gen_loss=6.437113, dis_loss=0.123998\n",
      "INFO: 18200: gen_loss=6.267398, dis_loss=0.166431\n",
      "INFO: 18300: gen_loss=6.324668, dis_loss=0.124251\n",
      "INFO: 18400: gen_loss=6.278091, dis_loss=0.041959\n",
      "INFO: 18500: gen_loss=7.184409, dis_loss=0.020738\n",
      "INFO: 18600: gen_loss=6.569182, dis_loss=0.166092\n",
      "INFO: 18700: gen_loss=6.153428, dis_loss=0.162524\n",
      "INFO: 18800: gen_loss=5.516523, dis_loss=0.084014\n",
      "INFO: 18900: gen_loss=6.464654, dis_loss=0.136718\n"
     ]
    }
   ],
   "source": [
    "engine.run(data=iterate_batches(envs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f520ba1-7d3a-4bcb-b59d-b3cc4733bfe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DRLH]",
   "language": "python",
   "name": "conda-env-DRLH-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
